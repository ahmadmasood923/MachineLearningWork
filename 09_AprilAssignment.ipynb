{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f140c94c-9d41-4ac6-8fc3-bb0bb30b65d1",
   "metadata": {},
   "source": [
    "## Ques 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8513c51-5768-469d-9223-b898e5379599",
   "metadata": {},
   "source": [
    "### Ans: Bayes' theorem is a fundamental theorem in probability theory that describes the relationship between the conditional probabilities of two events. It states that the probability of an event A given the occurrence of another event B is equal to the product of the probability of event B given event A and the prior probability of event A, divided by the marginal probability of event B. In other words, Bayes' theorem provides a way to update our beliefs about the probability of an event based on new evidence or information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3342439b-0be7-4864-917c-5bb9bfd481ea",
   "metadata": {},
   "source": [
    "## Ques 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2802ddbb-5b6b-4979-bdf9-05151f20dbbc",
   "metadata": {},
   "source": [
    "### Ans: Bayes' theorem can be mathematically represented as follows:\n",
    "### P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "### where:\n",
    "### P(A|B) is the posterior probability of event A given event B\n",
    "### P(B|A) is the conditional probability of event B given event A\n",
    "### P(A) is the prior probability of event A\n",
    "### P(B) is the marginal probability of event B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277ecd99-598c-4213-bad1-dc08ec87b4f3",
   "metadata": {},
   "source": [
    "## Ques 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d8e7ae-d497-4128-b24e-798b67a21fad",
   "metadata": {},
   "source": [
    "### Ans: Bayes' theorem has a wide range of applications in various fields, including statistics, machine learning, artificial intelligence, and decision-making. Here are a few examples of how it can be used in practice:\n",
    "### Bayesian inference: Bayes' theorem is used in Bayesian inference to update the prior belief about a parameter or hypothesis based on new data or evidence. This is commonly used in fields such as data analysis, forecasting, and risk management.\n",
    "### Spam filtering: Bayes' theorem is used in spam filtering to classify emails as spam or non-spam. The classifier uses the probability of certain words or phrases occurring in spam and non-spam emails to compute the probability of a new email being spam or non-spam.\n",
    "### Medical diagnosis: Bayes' theorem is used in medical diagnosis to calculate the probability of a patient having a certain disease given the results of medical tests and the patient's symptoms. This helps doctors make informed decisions about patient care and treatment.\n",
    "### Machine learning: Bayes' theorem is used in various machine learning algorithms, including Naive Bayes classifiers, Bayesian networks, and Bayesian regression. These algorithms use the theorem to model the probability distribution of data and make predictions based on new observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6acc600-36b3-493d-96d3-a5885cfad64e",
   "metadata": {},
   "source": [
    "## Ques 4:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fbb58b-0be6-41de-a5ca-8941e4f69143",
   "metadata": {},
   "source": [
    "### Ans: Bayes' theorem describes the relationship between conditional probabilities of two events. It shows how to compute the probability of one event given the occurrence of another event, taking into account prior knowledge or beliefs.\n",
    "### Specifically, Bayes' theorem relates the conditional probability of event A given event B to the conditional probability of event B given event A, the prior probability of event A, and the marginal probability of event B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8e19ee-f055-40f1-a91b-660b3ff08f2c",
   "metadata": {},
   "source": [
    "## Ques 5:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f4199b-0ef2-4d48-989c-773497f581e7",
   "metadata": {},
   "source": [
    "### Ans: The choice of Naive Bayes classifier depends on the type of data you have and the assumptions you can make about the probability distribution of the features. Here are some guidelines for choosing the appropriate type of Naive Bayes classifier for a given problem:\n",
    "### Gaussian Naive Bayes: Use this classifier when the features are continuous and assumed to follow a Gaussian (normal) distribution. This classifier is commonly used in problems involving numerical data.\n",
    "### Multinomial Naive Bayes: Use this classifier when the features are discrete and represent counts or frequencies of events, such as word frequencies in text data. This classifier is commonly used in problems involving text classification or document analysis.\n",
    "### Bernoulli Naive Bayes: Use this classifier when the features are binary or Boolean, representing the presence or absence of a feature. This classifier is also commonly used in text classification, especially for problems where the absence of a word is important information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6299b9b-f911-4510-9855-3715c5130d76",
   "metadata": {},
   "source": [
    "## Ques 6:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f820031-4664-425a-95ae-e3fc607cf604",
   "metadata": {},
   "source": [
    "### Ans: To use Naive Bayes, we need to calculate the posterior probabilities for each class given the values of the features X1=3 and X2=4. We can do this using Bayes' theorem:\n",
    "### P(A|X1=3,X2=4) = P(X1=3,X2=4|A) * P(A) / P(X1=3,X2=4)\n",
    "### P(B|X1=3,X2=4) = P(X1=3,X2=4|B) * P(B) / P(X1=3,X2=4)\n",
    "### We can calculate the likelihood probabilities P(X1=3,X2=4|A) and P(X1=3,X2=4|B) by multiplying the probabilities of the individual feature values for each class:\n",
    "### P(X1=3,X2=4|A) = P(X1=3|A) * P(X2=4|A) = 4/13 * 3/13 = 12/169\n",
    "### P(X1=3,X2=4|B) = P(X1=3|B) * P(X2=4|B) = 1/7 * 3/7 = 3/49\n",
    "### The prior probabilities P(A) and P(B) are equal, so we can ignore them for now. To calculate the evidence probability P(X1=3,X2=4), we can use the law of total probability:\n",
    "### P(X1=3,X2=4) = P(X1=3,X2=4|A) * P(A) + P(X1=3,X2=4|B) * P(B)\n",
    "### = 12/169 * 0.5 + 3/49 * 0.5\n",
    "### = 0.047\n",
    "### Now we can calculate the posterior probabilities:\n",
    "### P(A|X1=3,X2=4) = 12/169 * 0.5 / 0.047 = 0.53\n",
    "### P(B|X1=3,X2=4) = 3/49 * 0.5 / 0.047 = 0.47\n",
    "### So Naive Bayes would predict the new instance to belong to class A, since it has a higher posterior probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b92507-ce52-49fd-9e2f-1ac782e459fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
