{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbb78f64-571c-4520-84ba-2d3447642e28",
   "metadata": {},
   "source": [
    "## Ques 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf3f899-ceb7-4c7e-b3e6-71a284356eb3",
   "metadata": {},
   "source": [
    "### Ans: Ordinal encoding and label encoding are both techniques used for converting categorical data into numerical format. The main difference between them is the way they assign numerical values.\n",
    "### Ordinal encoding assigns a numerical value based on the order or hierarchy of the categories. For example, if we have a variable with categories \"low\", \"medium\", and \"high\", we can assign them values 1, 2, and 3 respectively, since \"high\" is considered greater than \"medium\" and \"medium\" is greater than \"low\".\n",
    "### Label encoding, on the other hand, assigns a unique numerical value to each category without considering any order or hierarchy. For example, if we have a variable with categories \"red\", \"green\", and \"blue\", we can assign them values 1, 2, and 3 respectively, without any consideration of which color is greater or lesser than the others.\n",
    "### In general, ordinal encoding is used when there is a clear order or hierarchy among the categories, while label encoding is used when there is no such order or hierarchy. For example, in a survey question about level of education, where categories are \"primary school\", \"high school\", \"college\", and \"graduate school\", ordinal encoding would be appropriate. In a survey question about favorite color, where categories are \"red\", \"green\", and \"blue\", label encoding would be appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27b9428-e3d4-4ff0-8118-b0b055dd630b",
   "metadata": {},
   "source": [
    "## Ques 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8391e0d0-f57a-4ce9-98b1-e07ddb60f956",
   "metadata": {},
   "source": [
    "### Ans: Target Guided Ordinal Encoding is a feature encoding technique that is used to encode categorical variables into numerical variables in machine learning. This technique is particularly useful when the categorical variables have an inherent ordering, and the target variable has a strong correlation with this ordering.\n",
    "### In Target Guided Ordinal Encoding, each category is assigned a numerical value based on its relationship with the target variable. The basic idea is to calculate the mean of the target variable for each category and then assign a numerical value to the category based on the mean value. The category with the highest mean is assigned the highest numerical value, and so on.\n",
    "### For example, let's say we have a dataset containing information about customers of an e-commerce store. One of the categorical variables in the dataset is the customer's income level, which has categories such as \"low\", \"medium\", and \"high\". We want to predict whether a customer will make a purchase or not based on their income level.\n",
    "### Using Target Guided Ordinal Encoding, we can assign numerical values to the income level categories based on the mean purchase rate for each category. For instance, if the mean purchase rate for the \"high\" income category is 0.8, \"medium\" is 0.6, and \"low\" is 0.4, we can assign the numerical values 3, 2, and 1 to these categories, respectively.\n",
    "### Then we can use these numerical values in our machine learning model instead of the original categorical values. This encoding can help capture the inherent ordering of the categories and improve the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d853d67-475c-4aac-a94b-1a4bc4317345",
   "metadata": {},
   "source": [
    "## Ques 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec806251-4b18-42c6-bcac-29307dc5d643",
   "metadata": {},
   "source": [
    "### Ans: Covariance is a statistical measure that describes the relationship between two random variables. It indicates how much two variables change together, and whether they have a positive, negative, or zero correlation.\n",
    "### Covariance is important in statistical analysis because it helps us understand the degree to which two variables are related to each other. Specifically, a positive covariance indicates that the two variables tend to increase or decrease together, while a negative covariance indicates that as one variable increases, the other decreases. A covariance of zero indicates that there is no relationship between the two variables.\n",
    "### Covariance is calculated by taking the product of the difference between each variable's value and its mean, and then taking the average of all those products. The formula for covariance between two variables X and Y is:\n",
    "### cov(X, Y) = (1 / n) * Σ[(Xi - X̄) * (Yi - Ȳ)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f366b9f6-9c4a-438f-a3c9-303ef807611e",
   "metadata": {},
   "source": [
    "## Ques 4:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80f4a93-d0f1-42ec-a3ac-45ee9d554ec7",
   "metadata": {},
   "source": [
    "### Ans: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c8adb86-b717-4b44-9050-5a84ebf15b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Color  Size  Material\n",
      "0      2     1         2\n",
      "1      0     2         0\n",
      "2      1     0         1\n",
      "3      1     2         2\n",
      "4      2     1         0\n",
      "5      0     1         1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# create example data\n",
    "data = {'Color': ['red', 'blue', 'green', 'green', 'red', 'blue'],\n",
    "        'Size': ['medium', 'small', 'large', 'small', 'medium', 'medium'],\n",
    "        'Material': ['wood', 'metal', 'plastic', 'wood', 'metal', 'plastic']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# initialize LabelEncoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# encode categorical variables\n",
    "df['Color'] = le.fit_transform(df['Color'])\n",
    "df['Size'] = le.fit_transform(df['Size'])\n",
    "df['Material'] = le.fit_transform(df['Material'])\n",
    "\n",
    "# print encoded data\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695aa24f-6a47-4b54-8e18-032d2fae7465",
   "metadata": {},
   "source": [
    "## Ques 5:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ff43b0-8bc9-4eae-98da-9441a6a5149e",
   "metadata": {},
   "source": [
    "### Ans: To calculate the covariance matrix for Age, Income, and Education level, we need to first calculate the covariance between each pair of variables. The resulting matrix will be a 3x3 symmetric matrix, where the diagonal elements represent the variances of each variable, and the off-diagonal elements represent the covariances between pairs of variables. Assuming we have a dataset with the variables Age, Income, and Education level, we can calculate the covariance matrix using Python's NumPy library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4947fd8c-adc5-4f5d-a4d0-af8a75bda87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.25e+01 1.25e+05 2.50e+01]\n",
      " [1.25e+05 2.50e+08 5.00e+04]\n",
      " [2.50e+01 5.00e+04 1.00e+01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# create example data\n",
    "data = {'Age': [25, 30, 35, 40, 45],\n",
    "        'Income': [40000, 50000, 60000, 70000, 80000],\n",
    "        'Education': [12, 14, 16, 18, 20]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# calculate covariance matrix\n",
    "cov_matrix = np.cov(df.T)\n",
    "\n",
    "# print covariance matrix\n",
    "print(cov_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f36837-264d-4fee-b1c4-3c8ecb851e79",
   "metadata": {},
   "source": [
    "## Ques 6:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473dcd09-b72c-4c4b-b092-25f947659725",
   "metadata": {},
   "source": [
    "### Ans: For each of the categorical variables in the dataset, we need to choose an appropriate encoding method to convert them into numerical values that can be used in a machine learning model. Here are some options for each variable:\n",
    "### Gender (Binary Categorical Variable): Since there are only two categories, Male and Female, we can use binary encoding. This involves mapping one category to 0 and the other category to 1. For example, we could map Male to 0 and Female to 1.\n",
    "### Education Level (Nominal Categorical Variable): Since there is no inherent ordering to the categories, we can use one-hot encoding. This involves creating a new binary column for each category, where a value of 1 indicates that the observation belongs to that category and a value of 0 indicates it does not. For example, we could create columns for High School, Bachelor's, Master's, and PhD, and mark each observation with a 1 in the column corresponding to its education level.\n",
    "### Employment Status (Ordinal Categorical Variable): Since there is an inherent ordering to the categories (Unemployed < Part-Time < Full-Time), we can use ordinal encoding. This involves mapping the categories to integer values based on their order. For example, we could map Unemployed to 0, Part-Time to 1, and Full-Time to 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367b7524-e79e-44b8-b1c8-5fd50e5ba079",
   "metadata": {},
   "source": [
    "## Ques 7:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a4b937-fad1-41b0-84d1-a42511ab2098",
   "metadata": {},
   "source": [
    "### Ans: To calculate the covariance between each pair of variables, we need to first separate the continuous and categorical variables, and then calculate the covariance between each pair of continuous variables. Since covariance is not defined for categorical variables, we cannot calculate the covariance between a continuous and a categorical variable. Assuming we have a dataset with the variables Temperature, Humidity, Weather Condition, and Wind Direction, we can calculate the covariance matrix between Temperature and Humidity using Python's NumPy library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57108c35-92be-4a49-8330-ef1a81364cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[62.5 62.5]\n",
      " [62.5 62.5]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# create example data\n",
    "data = {'Temperature': [20, 25, 30, 35, 40],\n",
    "        'Humidity': [30, 35, 40, 45, 50],\n",
    "        'Weather Condition': ['Sunny', 'Cloudy', 'Rainy', 'Sunny', 'Cloudy'],\n",
    "        'Wind Direction': ['North', 'South', 'East', 'West', 'North']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# calculate covariance matrix for Temperature and Humidity\n",
    "cov_matrix = np.cov(df[['Temperature', 'Humidity']].T)\n",
    "\n",
    "# print covariance matrix\n",
    "print(cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eb75a5-f6ae-4512-b237-6ef10dd7d7cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
